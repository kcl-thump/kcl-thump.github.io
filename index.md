The Trust in Human-Machine Partnerships (ThUMP) project is funded by EPSRC  (EP/R033722/1) under the Trust, Identity, Privacy and Security in the Digital Economy 2.0 (TIPS2) call. 

The goal of this project is to advance the state-of-the-art in trustworthy human-AI decision-support systems. 

Started in February 2019, over three years the THuMP project will address the technical challenges involved in creating explainable AI (XAI) systems, with a focus on problems involving complex planning and resource allocation, so that people using the system can understand the rationale behind and trust suggestions made by the AI.

The research questions addressed by THuMP include:

1. What are the technical challenges involved in creating Explainable AI Planning systems?

2. What are the technical, legal and social challenges involved in instantiating with explanations a planning system for solving resource allocation problems in critical domains? 

3. What are the legal and social implications of enhancing machines with transparency and the ability to explain? 

This project is done in collaboration with three project partners: Save the Children and Schlumberger that provided use cases for the project, and the law firm Hogan Lovells that will cooperate in investigating the legal implications of enhancing machines with transparency and explanations, and how this affects liability and accountability of machines and shared responsibilities.

